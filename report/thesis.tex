%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Sample document ``thesis.tex''
%%

% Available documentclass options:
% - <all `report` document class options, e.g.: `a5paper`>
\documentclass[]{simple-thesis}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Some mods
%%
\usepackage{graphicx}
\usepackage{courier}
\usepackage{listings}
\usepackage[margin=1cm]{caption}
\usepackage[toc]{appendix}
\usepackage{array}
\usepackage{float}
\usepackage{csquotes}
\usepackage{subcaption}
\newcolumntype{C}{>{\centering\arraybackslash}p{1.5cm}}
\renewcommand{\labelitemii}{$\circ$}  % Set the nested itemize style to empty circle.
\lstset{
  basicstyle=\footnotesize\ttfamily,
  numbers=left
}
\newcommand\fnurl[2]{%
  \href{#2}{#1}\footnote{\url{#2}}%
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis meta-information
%%

%% The title of the thesis:
\title{UnsocialVR: Faking active listening in social virtual environments}

%% The full name of the author (e.g.: James Smith):
\author{Tom Gurion}

%% Affiliation:
\affiliation{Media and Arts Technology\\Queen Mary University of London}
\affiliationlogo{CollegeShields/QMUL}

%% You can redefine the submission notice [optional]:
\submissionnotice{
  Supervisor:\hfill Host:\\Patrick Healey\hfill Inition
}

%% PDF meta-info:
\hypersetup{pdfkeywords={social VR, fake, attention, active listening}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{%
  TODO abstract...
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{%
  I wish to thank my supervisor Patrick Healey for his helpful and insightful guidance at every stage of the project, and for the positive feedback along the way.
  Huge thanks to my host Stuart Cupit at Inition for his support on this project.
  Special thanks to Pedro Souse from Inition who helped and directing me with technical advice, without him I wouldn't have the knowledge to make this project a reality.
  Thanks also to Inition's developers, Grigor and Kevin, for helping me learning so many new things in such a short time.
  For George and Peter for helping in setting up my experiments.
  For the rest of the people at Inition for their support, valuable feedback, and welcoming attitude.
  Thanks for Karen Shoop and Becky Stewart that provided guidance in the early stages of the project.
  Finally, thanks to the rest of the MAT cohort for the many invaluable conversations on all aspects of the project.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}

\frontmatter{}  %% Title page, abstract, TOC, etc.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%
\setcounter{page}{1}  % Start page count from here
\chapter{Introduction}

Meetings can be boring.
And still, showing your boredom is socially inappropriate.
During a meeting, or any group conversation for that matter, there is an implicit expectation from everybody to pay attention.
This is regardless of the fact that ones undivided attention is often not necessary for the purpose of the conversation.
Also, boredom is not the only behaviour we try to hide in these contexts.
We may want to drop from the conversation, just for a moment, for sending a text message, making sure we added milk to our grocery list, or having a short chat with the person next to us without anyone noticing.
And we want to be able to do these things without leaving the conversation completely.

In Infinite Jest, David Foster Wallace argues that ``Good old traditional audio-only phone conversations allowed you to presume that the person on the other end was paying complete attention to you while also permitting you not to have to pay anything even close to complete attention to her.'' \citep{Wallace1996}.
He continues and claims that we are addicted to this illusion, and that's why video conferencing often feel so awkward --- we need to pretend to listen all the time.
The implications are clear.
Telephony, as a medium, allows us to do all those things we wish were possible in face-to-face conversations and skype calls without being caught.
Furthermore, the telephony example highlightss the difference between leaving the conversation and faking attention.
It is always possible to tell the person on the other end that we need to leave, and must terminate the call.
Choosing not to do so, but fake attention instead, shows our interest in keeping the conversation going.

This project attempts to transfer this possibility, of faking attention, to multiparty conversations in virtual reality (VR) environments.
In Unsocial VR users share the same environment, using VR headsets and controllers.
They can converse and move freely, and have simple interface to start faking active listening behaviours.
During faking, an automated mechanism takes control over the user's avatar and performs socially appropriate behaviour on their behalf.
The interface is minimal.
Press a button on the handheld controller to starts the automated behaviours, and release it when you want to jump back to the conversation.
Users even get an on screen notification when someone is speaking directly to them, so they can return to the conversation elegantly.

The Unsocial VR system might therefore shed a light on the ways we signal attention to others, what it takes to automatically replicate these social signals, and how it affect the conversation.
As such, it is added to a growing list of social studies that chooses VR as a tool for research.
More generally, it can be seen as a an environment to investigate complex multiparty social behaviours.

Chapter \ref{literature_review} reviews the topics that form the basis for the current study.
Chapter \ref{system_design_and_implementation} presents the design and development of a system that was implemented especially for this research, and includes detailed motivation for each design decision.
A controlled experiment and its results are discussed in chapter \ref{evaluation}.
The report is concluded, in chapter \ref{conclusions}, by highlighting the main findings, the importance of their contribution, and suggestions for future work.


\chapter{Literature review}\label{literature_review}

The current study is based on multidisciplinary research.
It is embedded in a collaborative virtual environment (CVE), and employs asymmetric rendering techniques that are inspired by transformed social interaction (TSI) theories.
In addition, it implements mechanisms to fake active listening behaviours that are based on research in the field of embodied conversational agents (ECAs) and multiparty conversations.

\section{Collaborative virtual environments}

Collaborative virtual environments (CVEs) are computer systems that generate 3D avatars to represent human participants in a shared virtual space \citep{Bailenson2004}.
Recent technological breakthroughs made CVEs a possible advancement for both telecommunication and social research.
This section presents the advantages of using CVEs for both use cases.

Telecommunication technologies often tries to maximize the feeling of being together at a remote location.
This feeling, known as \textit{social presence}, varies between different communication media \citep{Short1976}.
For example, video conferencing is often described as a medium that supports higher social presence than, let's say, text-only chats.
But video conferencing is still way behind face-to-face conversation in many senses.
In multiparty conversation, its shortcomings include decreased turn taking efficiency, inability to participate in side conversations, lack of meaningful gaze, and no 3 dimensional orientation \citep{Isaacs1994}.

CVEs attempt to solve some of these issues by exposing socially significant cues in the virtual environment.
One of these cues, that is not redundantly coded in speech, and is usually problematic in video conferencing, is gaze.
CVEs that convey gaze give clear indication of who is talking with whom, and therefore simplify the turn taking management \citep{Vertegaal1999, Vertegaal2003}.
In addition, researchers show that exposing the users eye gaze in the virtual environment improved their lying detection \citep{Steptoe2010}.

Other studies explore the effects of non-verbal cues on communication.
For example, participants in CVEs that track and render head movements report higher social presence compared to environments with static, non-moving, heads.
Participants in the first condition also report that they like each other more, and look more on the other participant head \citep{Bailenson2002}.
Similarly, when trying to communicate the meaning of a word, users use less worlds when their listener's hand movements are presented in the virtual environment \citep{Dodds2011}.
In addition, when the listener's hands are static the speaker choose to skip words more frequently, without communicating their meaning.

Recently, the interest in CVEs started to spread beyond the research community.
Social VR attempts to bring CVEs to social media users with tight integration with existing and new social media platforms \citep{Bonasio2016}.
It is of no surprise that reviews of these commercial products tend to highlight known CVEs advantages compared to other ways of communication.
Namely, the possibility to create eye contact, the use of body language, free movement, higher social presence, and more \citep{Rosedale2015}.
Eye tracking is not yet supported by any social VR product.
The reason is probably the lack of available consumer VR headsets to support this feature.
Regardless, introducing eye tracking to social VR seems to be a natural step forwards \citep{Langley2017}.
Yet again, the lessons learned from research in non-verbal cues in CVEs are inline with the market demands.

The use of CVEs is, however, not bounded to telecommunication and social media.
They are also a viable tool for social research.
Traditionally, controlled experiments often explore psychological and social concepts out of context, in a laboratory environment.
Consequently, the ecological validity of the results might be unclear.
VR provides a possible remedy to this issue.
With it, controlled experiments can preserve the social context and therefore increase the results' ecological validity \citep{Loomis1999}.
Researchers also suggest that VR might solve additional common issues in psychology research: the lack of replications, and unrepresentative sampling.
First, when the entire experiment is done in VR, instead of a complex laboratory setup, replication studies might be easier to perform.
Second, consumer VR products are soon to become widespread, and with the emergence of social VR more users interact daily with VR content\footnote{VR market forecast: \href{http://uk.businessinsider.com/virtual-reality-headset-sales-explode-2015-4}{uk.businessinsider.com/virtual-reality-headset-sales-explode-2015-4}.}.
In the near future, VR might help mitigating the unrepresentative sampling issue by allowing scientist to run experiments with remote participants.
With the right consumer technology, it is not impossible that participation in immersive social experiments will become as simple as filling an online survey \citep{Blascovich2002}.

\section{Transformed social interaction}

Designers of CVEs can apply methods to strategically manipulate the social interaction.
These manipulations may decouple the rendering of the avatars or the environment from the real interactants behaviour.
For example, the underlying physics of face-to-face conversation imply zero-sum gaze.
Meaning that if interactant A is gazing at B for 80\% of the conversation they can't gaze at C for more than 20\% of the conversation.
In CVEs, however, this rule doesn't necessarily apply.
CVEs can be designed to let listeners see the speaker as always looking at them, regardless of the speaker true orientation \citep{Beall2003}.

Transformed social interaction (TSI) theory explores methods that system designers may apply to strategically manipulate the social interaction in CVEs \citep{Bailenson2004}.
The theory of TSI categorize these methods to three groups.
First are transformations of self-representation.
The non-zero-sum gaze example presented above fall under this category, as it manipulates the avatars represented in the system.
Second are enhancements to sensory capabilities.
The CVE itself can gather socially relevant information, process it, and present it for the benefits of the interactants.
For example, lecturers often try to spread their gaze evenly between the learners in a classroom.
This should ensure that no learner is left behind, helps the lecturer in assessing the class understanding, and encourage participation.
CVEs for remote learning can trace lecturers gaze and notify them when they are not spreading their gaze evenly.
A study that implemented such CVE showed that lecturers spread their gaze more evenly, and suggested that it increased their ability to maintain joint attention \citep{Bailenson2008b}.
Lastly are modifications of the environment, also known as the contextual situation.
This type of TSI methods is probably the least investigated.
An example, however, might be a system designed to support rewinding of the conversation to view past time events.

Many studies explored the social effects of transforming self-representations in CVEs.
\citeauthor{Bailenson2005} found that speakers that automatically mimic the listener movements are more likable (\citeyear{Bailenson2005}).
Consequently, listeners maintained smaller interpersonal distance with them.
In a later study, \citeauthor{Bailenson2008a} showed that modifying self-representation in CVEs affects the participants self-esteem (\citeyear{Bailenson2008a}).
Participants with more attractive avatars tend to disclose more personal information and yet again maintain smaller interpersonal distance with others.
Surprisingly, the results were consistent even when the manipulation only affected the way participants view themselves in a virtual mirror, without any change to how others see them.

Other studies merged TSI methods with game-like mechanisms to explore the effects of asymmetric representation and communication.
\citeauthor{Dominguez2014} asymmetrically modified the color of avatars and assessed changes in individual and group performance in an online collaborative game (\citeyear{Dominguez2014}).
Their results, although only partially conclusive, highlight new ways to apply self-representation transformations in social cognition research.
The Human \& Dog computer game takes these ideas to the extreme by having one interactant play a human and one a dog in the virtual environment.
The communication channels between them is therefore asymmetrically restricted by the game design, with the intent to make the game more challenging and interesting \citep{Chou2016, Hou2017}.

Research in TSI raises some inevitable ethical dilemmas.
Put in the wrong hands, the ability to increase ones persuasion capabilities might be frightening.
TSI methods can even cause complete mistrust in CVEs and the refusal of users to participate in such environments.
Thankfully, the research community is not blind to these issues.
\citeauthor{Bailenson2008} interestingly argue that we already perform several similar methods in our day-to-day life (\citeyear{Bailenson2008}).
Being these make-up products that change our natural appearance, deodorants that suppress our body scents, or the choice of clothes, we often try artificial methods to improve.
We want to be perceived as more attractive in real life, and these aims are transferable to CVEs.
Furthermore, the society, more often than not, expects us to perform these artificial improvements.
It welcomes them, and doesn't portray them as faking.

\section{Active listening and embodied conversational agents}

In natural and engaging conversations interactants transmit a wide array of social cues.
These can indicate the parties interest in keeping the conversation going, show mutual understanding, or the attempt to take the speaker turn.
Whereas conversations are usually considered to be a lingual phenomena, many of these social signals are non-verbal (e.g.\ head nods and facial expressions), or paralingual (e.g.\ the use of prosody or utterances like ``uh-huh'').
In the context of active listening behaviours these are known as backchannels \citep{Yngve1970}.
A study that gave listeners in a dialogue demanding tasks that were unrelated to the conversation showed decreased fluency of the speaker.
This implies that listeners backchannel behaviours have a significant effect on the speaker \citep{Bavelas2000}.
These behaviours are also considered to be the basis on which rapport is built \citep{Tickle-Degnen1990, Gratch2007}.
Therefore, it is of no surprise that one of the main application for backchannels research is the automation of embodied conversational agents (ECAs).
Integrating backchannels into such agents might be the key to providing socially appropriate responses in free conversation \citep{Morency2008, Bevacqua2008}.

Researchers often use surface features like speaker-listener eye contact, speaker voice level, and prosody to model backchannels.
\citeauthor{Ward2000} suggested a backchannel prediction model that is based on the speaker prosody (\citeyear{Ward2000}).
Their model uses a small set of features and simple hand-crafted rules.
Specifically, speaker ``talking state'' (speaking or silent) and the pitch of the speaker voice were taken into account.
\citeauthor{Gratch2006} propose to incorporate the speaker head moves and body pose into a similar model (\citeyear{Gratch2006}).
\citeauthor{Lee2006}, on the other hand, suggested to use surface text features to predict backchannels (\citeyear{Lee2006}).
They used a bag-of-words technique, with different spoken words triggering different listener responses.
They based their rules on manual analysis of conversations with ECAs that were video recorded.
All of these studies use a set of carefully chosen rules to build their backchannel prediction models.

Recent studies suggest data-driven approaches for backchannels modeling to improve predictive performance.
\citeauthor{Nishimura2007} predict listener responses using the pitch and power of the speaker voice (\citeyear{Nishimura2007}).
Their model, however, isn't constrained to predict backchannels only.
A response generator uses audio features to choose between backchannels, collaborative completions (e.g. suggesting a keyword for the speaker), and other types of response.
Their decision-tree model was trained using audio-recorded and annotated conversations of the RWC multimodal database \citep{Hayamizu1996}.
\citeauthor{Morency2008} followed a similar path but with a more exhaustive set of audio-based features, and speaker-listener gaze annotations (\citeyear{Morency2008}).
In addition, they encoded each feature with a set of encoding templates that modified the appearance of the feature over time.
Then, they applied probabilistic methods to choose the feature with the most predictive power to incorporate into the model.
\citeauthor{Huang2011} uses a simplified model that is based only on non-verbal information (\citeyear{Huang2011}).
Their model uses the speaker talking state, speaker-listener eye contact, and, interestingly, the speaker smile, to predict listener backchannels.
A year later, \citeauthor{Kok2012} suggested some improvements to the same model to make it more robust to different speaker behaviours (\citeyear{Kok2012}).
Note that there is almost no direct comparison between the different models, mainly due to the use of different datasets and different evaluation methods \citep{Morency2008}.

\section{Active listening in multiparty conversations}

In any single moment a participant in a dyadic conversation is either a speaker or a listener.
Understanding multiparty conversations, however, requires a larger set of roles.
Some of these are more obvious, like the role of the speaker, whereas the differences between other roles might be harder to tell.
According to \citeauthor{Clark1982}, apart from the speaker, participants in a conversation can take a role of addressees, side-participants, and over-hearers (\citeyear{Clark1982}).
Put simply, addressees are the listeners that the speaker voice is directed to.
Side-participants are the listeners that the speaker wish to inform when speaking with the addressees.
By doing so, the accumulated knowledge of the conversation is shared between all of its participants.
The side-participants are usually not expected to take the floor.
Over-hearers are listeners that the speaker have no interest in them hearing the conversation.
They are less relevant for the current study and thus won't be further discussed.
The roles are usually assigned to the participants, implicitly, by the speaker.

Not surprisingly, experimental studies found behavioural differences between addressees and side-participants.
Speakers often change orientation and assign the addressee role to side-participants if they provide more backchannels than the addressees \citep{Goodwin1979}.
Another study showed that when speakers look at side-participants, the side-participants often look back at the speaker.
One the other hand, the same doesn't apply for addressees.
When the speaker rotate from them and towards the side-participants they usually keep looking at the speaker \citep{Healey2009}.
A follow up study by the same researchers confirmed the common belief that in 3 party conversations addressees usually look at the speaker.
Interestingly, the side-participants are equally likely to look at the addressee.
This finding disagree with the common assumption that side-participants look where the speaker is looking \citep{Battersby2010}.
Moreover, unlike addressees, side-participants usually suppress backchannels as the speaking rate increases \citep{Healey2013}.

To my knowledge, these findings were never used for automating ECAs.
Most of the efforts in ECAs research are currently concentrated on two party conversations.
Two studies, however, are worth mentioning, as they model agents to perform in multiparty contexts.
\citeauthor{Matsusaka2001} present a robot that can join multiparty conversations (\citeyear{Matsusaka2001}).
Apart from the implementation of a turn taking mechanism, the researchers chose to implement the robot as always looking at the speaker.
In case of no current speaker, the robot uses the turn taking mechanism to anticipate the next speaker and rotate to that direction.
In addition, this system restricted to 3 party conversations only.
Interestingly, the authors claim that when there is more than one side-participant, as implied by conversations with more than 3 parties, the modeling of the agent attention should take the other side-participant in mind, and these complexity is out of the scope of their research.
A clear reasoning behind this statement and the decision to always rotate the robot towards the speaker are missing from the paper.
According to the authors in more the authors claim
A similar study was conducted by \cite{Fujie2009}.
Their paper, again, describes a robot that can participate in multiparty conversation.
The behaviour of the robot depends on its conversational role.
Moreover, in some of the behaviours or optional, depending on the role, as demonstrated bellow.
As a speaker, the agent must choose an addressee to look at and reply to the former speaker.
As an addressee, the agent must node appropriately and look at the speaker.
And as side-participant, it has the option to look at the speaker and can either node or not.
In all roles, if a target object is discussed the agent must look at it or point to it.
This basic set of rules reflects some of the findings of \cite{Healey2009} and \cite{Battersby2010}, and might provides good starting point for automating agents in multiparty contexts.


\chapter{System design and implementation}\label{system_design_and_implementation}

Whereas many studies explore active listening behaviours using ECAs \citep{Nishimura2007, Bevacqua2008, Gratch2007, Huang2011, Lee2006, Poppe2013}, the current research aim to investigate how humans can start to pretend to listen to someone, how they stop faking and return to the conversation, and what are the social implication for such behaviours.
Recently, social research see high opportunities in exploring social behaviours using virtual environments \citep{Loomis1999}.
Following the same trend, and inspired by the possibilities to fake attention in ways that are impossible in face-to-face conversation, the current research uses a specially developed CVE.

The main target of this CVE is to allow exploration of faked active listening behaviours in a multiparty social context.
Inside the virtual environment, a minimal user interface let participants start and stop faking.
Users press a button to perform faked active listening behaviour, meaning, that while the button is pressed other users won't see the real behaviour of the faker in the virtual environment.
Instead, the avatar of the faking user, as viewed by everyone else, will be controlled by an automated behaviour.
The three principles that enable this automation are presented in section \ref{system:mechanisms}.

Figure \ref{fig:system:diagram} shows a schematic diagram of the system architecture, and the paths and protocols of communication between the components.
In blue are the client side components.
The components in green are client facing servers, and the red ones are background servers that process behavioural data to instruct the client facing servers how to operate.
A thorough description of each component in the system is presented bellow.

The code for the entire project is open sourced and \fnurl{available online}{https://github.com/Nagasaki45/UnsocialVR}.

\begin{figure}
  \includegraphics[width=\textwidth]{../graphics/system_diagram.pdf}
  \caption{A schematic diagram of the system architecture. In blue are client side components, that communicate with the client facing servers in green. The components in red are background servers that are used by the client facing servers to process behavioural data. The lines between the components represents paths of communication with the a label indicating the protocol.}
  \label{fig:system:diagram}
\end{figure}

\section{Mechanisms for faking active listening behaviour}\label{system:mechanisms}

The underlying mechanisms that support the automation of the faking behaviour are a mixture of ideas.
Part of them are based on the scientific literature, while others are novel findings from the current research.

\subsection{Automated head nods}

As already discussed, carefully crafted automated head nods are known to be crucial for creating convincing ECAs.
Therefore, the current project follows the literature in the field and implements backchannel predictor using machine learning (ML) techniques.
This predictor is thoroughly described in section \ref{system:active_listening_server}.

\subsection{Baseline recorded movement}

When users trigger the automated behaviour their avatars must keep moving naturally.
They can't, for example, just freeze.
During the early development phases of the system the faked behaviour used a pre-recorded movement of the hands, head, and chest.
This pre-recorded movement was looped to support an arbitrary length of faking periods.
In addition, random time lag was added for the recorded movement of each user to make sure no two fakers look the same.

A short pilot study with 3 co-workers was conducted to uncover user experience issues with the system.
Participants in the pilot were not instructed to do any specific task in the virtual environment, nor fill any questionnaire before or after the experience.
In addition, no measurements were recorded.
Instead, I was interested to hear from the participants about their experience with the system, and probed them to emphasize their experience with the faking mechanism.

The results clearly show that the transitions into the automated behaviour are noticeable.
The change of body posture and the positioning change of the body parts between the real and the faked behaviour were easily detected.
The reason for that is that physical differences between people are recreated in the virtual environment.
Ignoring these and using the same movement for everyone allowed the participants to quickly learn to notice the pre-recorded behaviour.

As a solution, the system always record the last few seconds of each user.
When the user trigger the faked behaviour this recorded movement will start to play in a loop.
To make sure that there is no jump in the loop the recorded movement is first played backwards from the last recorded sample.
Whenever the playing head reaches the end of the recorded movement the playing direction flips.
More implementation details are described in section \ref{system:fake_behaviour_generator}.

Whereas preserving the personal body language and posture is the most obvious improvement, the proposed solution offers one additional, more subtle, advantage.
As already discussed, the role in the conversation have implications on the interactant body language.
Addressees, for example, are expected to behave differently than side-participants.
The new baseline recorded movement guarantees to match the last conversational role of the faker.

\subsection{Looking at the speaker}

With the head nods and the baseline recorded movement in place only modeling of attention is missing.
A basic approximation of attention in a conversation is to always look at the speaker, as suggested by \cite{Fujie2009}.
Therefore, the last underlying mechanism for the faked behaviour is to always slowly rotate towards the user that is currently speaking.
If no one is speaking, faking avatars rotate towards the last speaker.

\section{Hardware}

The hardware used in this project is the \fnurl{HTC Vive}{https://www.vive.com/uk/}, which bundles together a headset and two hand controllers.
In addition, a \fnurl{Vive tracker}{https://www.vive.com/uk/vive-tracker/} is used to track the chest position of each participant.
This setup provides suitable features for the project compared to products like the \fnurl{Oculus Rift}{https://www.oculus.com/rift/}, or simpler VR solutions like \fnurl{Google Daydream}{https://vr.google.com/daydream/} or \fnurl{Samsung Gear VR}{http://www.samsung.com/global/galaxy/gear-vr/}.
Specifically, the system make use of the following features of the headset that are absent from other products:

\begin{itemize}
  \item The headset and its controllers and trackers are tracked in 3 dimensional (3D) space of up to 6 x 6 meters, enough for freely wondering around in a virtual environment. Recently, the Oculus Rift started to provide similar capabilities but they are better supported by the HTC Vive.
  \item The ability to combine extra trackers, that are used in this project to track the chest of the participant, are not available in other products.
\end{itemize}

\section{Game Client}

The Game Client is the application each player uses to connect to the virtual environment.
Figure \ref{fig:system:3d_design:unsocial_vr} shows how the virtual environment and the avatars look like\footnote{Most of the 3D models were designed by me using blender (\href{https://www.blender.org/}{www.blender.org}), an open source 3D creation software.}.

I choose to contextualize the environment as a cocktail party on the beach.
This decision is mainly influenced by the intent to create a shared space where people can interact and dynamically form conversational groups.
Note that cocktail parties are common examples for such environments in the scientific literature \citep{Setti2015}.

The design of the player avatar adhere to the following principles.
First, the avatars are designed in a cartoon-ish and unrealistic style.
This is inline with similar decision by commercial social VR products\footnote{AltspaceVR blog post on avatar design: \href{https://altvr.com/social-communication-design-in-vr/}{altvr.com/social-communication-design-in-vr}.} \citep{Ghosh2017, Pot2016}.
For reference, the social VR platform from facebook, \fnurl{Facebook Spaces}{https://www.facebook.com/spaces}, is presented in figure \ref{fig:system:3d_design:facebook_spaces}.
Also, attempts to design a realistic avatar often elicit feelings of eeriness and revulsion.
This effect, also known as the \textit{uncanny valley}, suggests that when robots become more human like, our empathy to them increase.
It is true until a point of high similarity to humans where there is a ``valley'' in the empathy curve \citep{Mori1970}.
The unrealistic avatars made it easy to stay away from the uncanny valley.
Second, the avatar is made out of 4 body parts: head, 2 hands, and chest.
The aim of this is to immerse the players in the experience and makes them more aware of their bodies.
In addition, the chest is also used to signal the body orientation and therefore might indicate attention and provide sense of belonging to a conversation.
Originally, the cartoon style of the avatar made the orientation unclear.
To solve this, a belt with a buckle helps indicating the body direction.
Third, to avoid unnecessary biases the avatars are gender-natural.
Lastly, the mouth is animated when the player is speaking.
All players have the same avatar, so it is often hard to distinguish them.
The simple indication for who is currently speaking provided by the mouth movement makes the interaction more fluent and natural.

The players interface is minimal.
There is one button on the controller that when pressed, the player starts to fake active listening behaviour.
When the button is released the faked behaviour stops and the player jumps back to the place and orientation where the faking behaviour started.
This gives the players the freedom to start faking active listening and jump back to the conversation as fast as possible when needed.
As in other HTC Vive games, one of the controller's buttons implements a ``teleportation'' feature that make movement in the environment faster and easier (like in \fnurl{The Lab}{http://store.steampowered.com/app/450390/The_Lab/} game).
In addition, while a player that fake active listening is approached by another player, a notification saying that ``someone is talking to you'' appears, suggesting that it's time to stop faking and going back to the conversation.

The client is developed using the free game development platform \fnurl{Unity3D}{https://unity3d.com/}.
The integration of the hardware with Unity3D is seamless, and both have large communities of developers, making Unity3D a natural technological choice.

A voice chat is implemented into the client.
Early versions of the client muted players when they started faking, but in a pilot study this behaviour was found to be complex and non-intuitive for the users.
Therefore, voice chat is always open, regardless of whether the player is faking or not.

The client application communicate with two other components over the network.
The first is the Identification Game Server.
Communication between the clients and this server is based on the native Unity3D networking library: UNet.
The second component that the client communicate with, over HTTP, is the Main Game Server.

A simulator client was created for testing and development purposes.
It uses the same environment and avatars, but is controlled by keyboard and viewed using the computer screen instead of the VR headset and controllers.

\begin{figure}
  \centering
  \begin{subfigure}{.4\textwidth}
    \centering
    \includegraphics[height=6cm]{../graphics/environment_demo.png}
    \caption{Unsocial VR}
    \label{fig:system:3d_design:unsocial_vr}
  \end{subfigure}%
  \begin{subfigure}{.6\textwidth}
    \centering
    \includegraphics[height=6cm]{../graphics/facebook_spaces.jpg}
    \caption{Facebook Spaces}
    \label{fig:system:3d_design:facebook_spaces}
  \end{subfigure}
  \caption{Example view of the virtual environment and the avatar design for Unsocial VR on the left and Facebook Spaces on the right.}
  \label{fig:system:3d_design}
\end{figure}

\section{Identification Game Server}

The Identification Game Server utilize the built-in Unity3D network server to create an identification for each connected client, and notify the rest of the clients about new connections.
Based on this information clients create and manage avatars for all of the players in the virtual environment.
In addition, the voice chat communication between the clients operates through this server.
Usually, the Unity3D network server is also used to pass positioning, orientation, and other kinds of information between clients.
In this project, however, most of the data is passed between the clients through the Main Game Server.

\section{Main Game Server}

The main game server is used to pass information between the clients.
Each client repeatedly sends the player information to this server and get back information about the other players.
This information includes the positioning and orientation of the chest, head, and hands of the player.
It also includes the identification of who the player is looking at, whether or not the player is speaking (using sound level threshold), and whether or not the player is currently faking.

On the server, first, the player data is extracted from the HTTP request and stored in an in-memory cache.
Then, information about the rest of the players is extracted from the cache.
For each of the non faking players, the information is passed to the client from the cache without modification.
Otherwise, the positioning and orientation are overridden by an automatic generated movement that is described thoroughly in section \ref{system:fake_behaviour_generator}.
Additionally, the player is flagged to be faking, and the identification of the current speaker is sent to the client.
This information is than used by the client to rotate the automated agent slowly towards the speaker.
I decided to implement this feature on the client side only for technical reasons:
Unity3D made it relatively straightforward to slowly rotate an object towards a specified direction, whereas on the server I would have to write this functionality from scratch.

The clients communicate with the server every 20 milliseconds, and interpolate the readings.
This fast communication is crucial for keeping the visual rendering smooth.
A faster communication rate found to overload the server.

The server is developed in \fnurl{Elixir}{https://elixir-lang.org/}.
Usually, when developing games in Unity3D the server is built with Unity3D as well.
The main reason for choosing Elixir instead is my prior familiarity with it.
In addition, Elixir provides some nice benefits for this type of project, as it significantly simplifies the development of both web and concurrent programs.
Lastly, being a high level language with terse syntax and many high quality libraries accelerated the development process.

\section{Active Listening Server}\label{system:active_listening_server}

The Active Listening Server is responsible for predicting head nods.
It is based on the vast research in automatic backchannel behaviours prediction and uses speaker talking state (is speaking or silence) and gaze (is looking at listener or not).
Predicting listeners backchannel behaviours is usually done using either hand-crafted rule based systems, or more recently, data driven and ML approaches \citep{Morency2008}.
Due to the better performance of the later, and with the absence of openly available solution, I decided to develop an ML based backchannel predictor for the project.
Using more features, such as prosody \citep{Ward2000} or speaker gestures \citep{Gratch2006}, could probably improve the model.
However, the simpler model described below was found to be accurate enough.

It is important to note that there is an expected difference in social behaviour between an addressee and a side-participant \citep{Clark1982}.
Although the addressee can fake active listening, in the context of the current research it is more common for side-participants to fake and wonder around, as they are not required to provide verbal response to the speaker.
However, there is much less literature about predicting side-participants active listening behaviours, and even less available resource for training a data-driven model.
With that in mind, the project predicts the addressee backchannels and applied them to both addressees and side-participants alike.

Training an ML model required a dataset of conversations with annotations for speaker talking state, gaze, and listener backchannels.
The ICT Rapport Dataset \citep{Gratch2007} contains 126 annotated interactions between a speaker and a listener, and is \fnurl{openly available online}{http://rapport.ict.usc.edu/}, making it ideal for training a backchannel predictor.
Many of the interactions, however, were not properly annotated.
Some of them doesn't contain all of the annotation files while other have blank columns for some of the features of interest.
After filtering out interactions with missing data the remaining 48 interactions had an average length of 138 seconds, ranging from 41 to 248 seconds.

The annotations were re-sampled every 100 milliseconds to prepare the data for training.
Then, to create samples representing a window moving in time, 30 samples (3 seconds) of the speaker talking state and gaze were concatenated into one vector.
This vector, when fed into the ML model, should predict the listeners nodding of the last sample.
As a last step of preparation the dataset was split into 3 to 1 train and test portions.

I tried to train three different ML models.
First was a Linear Support Vector Machine Classifier (LinearSVC) model from the open source software package Scikit-learn \citep{Pedregosa2011}.
Using the test portion of the dataset, the model precision (percentage of correct predictions) was high.
However, the recall (correct predictions out of correct predictions and misses) was very low.
In fact, the model learned to almost never predict a backchannel.
Visually comparing the predictions to the dataset reveals that it failed to model the data correctly.
Second was a Long Short-Term Memory (LSTM) deep neural network from the open source software package Keras \citep{Chollet2015}.
The results were similar to these of the LinearSVC model.
Lastly, I trained a K Nearest Neighbors classifier ($K = 5$) with Scikit-learn.
This time, it seems that the model manage to capture the nature of the data, as shown in figure \ref{fig:system:backchannel_predictions}.
Using the test portion of the dataset the accuracy was lower than before (0.77), but the recall was higher (0.83).

\begin{figure}
  \includegraphics[width=\textwidth]{../graphics/backchannel_predictions.pdf}
  \caption{An example of one interaction between a speaker and a listener from the ICT Rapport dataset, with both actual and predicted listener backchannel behaviours. The lines indicate the state of the features and prediction with values of either 0 when the line is low, or 1 when the line is high.}
  \label{fig:system:backchannel_predictions}
\end{figure}

Choosing between the models didn't follow a properly nor systematic evaluation.
However, based on the performance on the test portion of the dataset and visual inspection the K Nearest Neighbors classifier seemed to performed well enough.
It also provided fast predictions, as necessary by real-time system like this one.

To make the backchannel predictions more robust to variations in the input data the variable threshold as suggested by \cite{Kok2012} was implemented.
The K Nearest Neighbors classifier can be used not only to predict a backchannel, as a binary value, but also to predict the probability of a backchannel.
This feature of the model is used, together with a variable threshold to provide predictions.
Initially, the threshold is set to 1, and is decreased over time by 10 percent per second.
When the predicted probability for a backchannel accedes the threshold, a backchannel is predicted and the threshold resets back to 1.

This model, with the variable threshold algorithm, is written in \fnurl{Python}{https://www.python.org/} and exposes an HTTP endpoint.
The code for this server is open sourced and \fnurl{available online}{https://github.com/Nagasaki45/backchannel}.
The Main Game Server repeatedly fetches all of the currently faking players from the server cache and sends them, together with information about the speaker talking state and gaze, to the Active Listening Server.
The returned predictions are stored back in the Main Game Server cache.

\section{Fake Behaviour Generator}\label{system:fake_behaviour_generator}

The Fake Behaviour Generator integrate the predicted head nods from the Active Listening Sever with a natural baseline recorded movement.
It is designed to provide a smooth and socially appropriate movement for the automated behaviour.
For each player, the position and orientation of the head and hands, relatively to the chest, is always recorded.
This data is kept in a 2 seconds buffer.
The decision to keep the last 2 seconds is arbitrary and found via trial and error.
It aimed to give a long enough recording to make the faked behaviour look natural, but in the same time not to include two old movements.
If the faker was involved in different type of activity few seconds ago, like speaking for example, it is better to discard these body movements as they are probably inappropriate in the new context.
When a participant start to fake active listening a playback of this buffer starts from the last recorded sample and goes backwards until it reaches the beginning of the buffer, and then forwards again, repeatedly.
This ensure that there are no jumps in the playback of the recorded movement.

Lastly, the predicted head nods from the Active Listening Server are generating head nods animation that was created in Unity3D.
This animation is merged (position vectors are added together) with the rest of the faked behaviour.


\chapter{Evaluation}\label{evaluation}

The system described in the previous chapter suggests several interesting evaluation paths.
In the current study, I choose to follow the extensive research already done in the field of ECAs \citep{Nishimura2007, Bevacqua2008, Gratch2007, Huang2011, Lee2006, Poppe2013} and frame the evaluation in that context.
Whereas all of these studies assess interaction with an automated agent, in the current project the interaction is with an avatar that switches between human and automated control.
In addition, research in the field of ECAs doesn't usually explore multiparty social interactions.
These differences opens up ways to explore the properties of the transition between the two modes, and the effects of the social context.
More specifically, can state of the art ECA techniques (e.g. automated backchannel behaviours) seamlessly replace human controlled avatars?
If so, for how long can automated behaviour replace us without anyone noticing?
What underlying mechanisms are required to support such automated behaviour?
And more importantly, what are the limitations of such methods and what can they tell us about active listening behaviours?

This chapter presents a controlled experiment that was done to evaluate the automated active listening properties of the system, with emphasis on the properties of the transition into the automated behaviour.
Specifically, I assess the time it takes for participants to detect a faked behaviour, the detection accuracy, and how are these affected by familiarity between participants.
In addition, the participants strategies for detecting faked behaviour are analyzed and compared to their performance.
This information have the potential to explain what underlying mechanism more easily expose the automated behaviour.

Note that the experiment design bellow contains only one condition.
Therefore, most of the results are descriptive statistics of the system and correlations between different measurements.
No comparisons to any control condition could be made.
Due to the absence of scientific literature on this specific use of automated social behaviour, this experiment design may still provide interesting results and a baseline for future research.

\section{Participants}

% How to report participants gender / age: http://evc-cit.info/psych018/Reporting_Statistics.pdf
Participants were 6 males and 6 females aged 23 to 52 years (male: M = 33.67, SD = 9.71; female: M = 27, SD = 2.53).
Most of the participants were co-workers, friends, and classmates, that responded to my call for participants on mailing lists and private messages.
They were allocated to 4 groups of 3 participants each based on their preferred participation time.
Participation was completely voluntary, as they didn't receive compensation.
Due to missing a participant in one of the group a co-worker re-participated in the experiment.
Examination of the group and the participant data didn't show any unique or unexpected differences from the other groups so I decided not to discard the groups' data.

\section{Materials}

The participants were asked to cooperate in a hot air balloon task \citep{Howes2012} in the virtual environment:
They were presented with a scenario of an hot air balloon that is about to crash, unless one passenger will be sacrificed.
They had to come to an agreement, and choose between scarifying a 7 months pregnant woman, her husband, the balloon pilot, or their friend, a doctor that is about to find the cure for cancer.

They were also instructed that there are tokens hidden in the virtual environment that they need to find and collect, whilst still progress towards their shared goal of the balloon task.
These tokens were presented only while faking, so to collect them they had to fake participation in the conversation.
Meanwhile, participants in the conversation could accuse whoever they think is faking active listening by looking at them and pressing a button on the hand controller.

A scoring mechanism was introduced to motivate the participants to use the faking behaviour:
Collecting a token gives 5 points.
A participant that correctly accuse another participant for faking stills one point from them.
However, if the accusation is incorrect, the accuser loses one point for the accused participant.

\section{Apparatus}

During the VR sessions the participants were divided into 3 network connected rooms, with one participant at each room.
They used the HTC Vive headset and controllers, with additional Vive Tracker for tracking chest positioning.
They were video recorded and their view of the VR environment was captured.
The following events were logged by the system for further analysis:

\begin{itemize}
  \item Transitions to and from faked behaviours.
  \item Every time a participant started or stopped talking.
  \item Accusations for faking active listening.
  \item Collection of a token.
\end{itemize}

\section{Procedure}

The experiment started by each participant filling a pre-experience questionnaire (see appendix \ref{appendix:questionnaire:pre}).
Then, the features and functions of the system were carefully explained using the instructions sheet found in appendix \ref{appendix:interface}.
Later, the participants entered the VR environment for 10 minutes familiarization session, after which the total score of each participant for this session was revealed.
Participants were encouraged to ask questions about the system to make sure they fully understand how to use the interface to operate their avatar.
Then, the hot air balloon task was explained and the main experiment session was started.
I instructed the participants to get to an agreement in up to 15 minutes.
After the participants formed a consensus, the VR experience stopped, and the participants filled a post-experience questionnaire (see appendix \ref{appendix:questionnaire:post}).

\section{Results}

Participants in the hot air balloon task reached a consensus by 10:41 to 14:49 minutes.
During that time, the ratio of correct accusations from all accusations made was 0.285.
This ratio, referred as \textit{detection performance}, is used interchangeably from now on to describe individual participants or the entire sample.
Although this value is surprisingly low, it is probably above chance level, as the average ratio of time spent faking out of the entire session length is 0.22.
The ratio of faking behaviours that started and finished without any accusation was 0.787.
As shown in figure \ref{fig:analysis:hist_time_faking}, longer faking periods were easier to detect ($t(341) = -4.826$, $p < .001$).

\begin{figure}
  \centering
  \includegraphics[width=.6\textwidth]{../graphics/analysis_hist_time_faking.pdf}
  \caption{A histogram of the time, in seconds, of all faking behaviours. In blue are faking behaviours that started and finished without other participants accusing the faker. In orange are the faking behaviours that were detected: another participant correctly accused the faker. The figure demonstrates both the ratio between undetected and detected faking behaviours and the difference in time between undetected and detected faked behaviours.}
  \label{fig:analysis:hist_time_faking}
\end{figure}

No significant correlation was found between VR expertise, age, or gender, and detection performance, talking, or faking behaviours.
Yet, a larger sample might suggest otherwise.
On the other hand, talking and faking behaviours found to correlate.
More specifically, participants that talked a higher percentage of the experiment also faked active listening more time ($r(10) = 0.65$, $p < .05$) and for longer periods ($r(10) = 0.66$, $p < .05$).
This relationship, that is shown is the left panel of figures \ref{fig:analysis:correlation_talking_ratio_vs_faking_time} and \ref{fig:analysis:correlation_talking_ratio_vs_faking_ratio}, is mainly affected by one outlier.
Without the outlier there is no significant correlation, and the trend even change its general direction as shown in the right panel of figures \ref{fig:analysis:correlation_talking_ratio_vs_faking_time} and \ref{fig:analysis:correlation_talking_ratio_vs_faking_ratio}.
Therefore, the correlation between talking and faking behaviours might be understood as a unique strategy applied by a single participant.
Indeed, the written comments confirm that this participant tried to talk as much as possible while faking to distract the other participants:

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{../graphics/analysis_correlation_talking_ratio_vs_faking_time.pdf}
  \caption{Both panels show a scatter plot and a regression line of the participants' talking ratio (talking time out of the entire session) compared to the average faking time in seconds. In the left panel outliers, marked with orange, are included in the calculation. On the right panel outliers are excluded from the scatter plot, regression line, and statistics.}
  \label{fig:analysis:correlation_talking_ratio_vs_faking_time}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{../graphics/analysis_correlation_talking_ratio_vs_faking_ratio.pdf}
  \caption{Both panels show a scatter plot and a regression line of the participants' talking ratio (talking time out of the entire session) compared to the faking ratio (faking time out of the entire session). In the left panel outliers, marked with orange, are included in the calculation. On the right panel outliers are excluded from the scatter plot, regression line, and statistics.}
  \label{fig:analysis:correlation_talking_ratio_vs_faking_ratio}
\end{figure}

\begin{displayquote}
  \textit{
    FAKE IT TILL YOU MAKE IT.
    I was FAKING 50\% of experience, idea was to keep on talking load of things to make people engage while I do my thing.
    I was also getting more personal in my speech so people can believe that I'm there with them.
  }
\end{displayquote}

In addition, a negative correlation was found between average faking length (in seconds) of each participant and the ratio of faked behaviour they completed without being accused ($r(10) = -0.72$, $p < .01$).
This is inline with the previous results that shows that detected faking behaviours are usually longer.
Similarly to the correlations found between talking and faking behaviours, this correlation is also affected by the same outlier, as shown in figure \ref{fig:analysis:analysis_correlation_faking_time_vs_faking_undetected}.
In this case, again, removing the outlier makes the result insignificant.
However, the outlier keeps the general trend, suggesting that the failure to get significance without the outlier is not due to different underlying characteristics but due to reduced statistical power.
Therefore, I suspect that indeed, participants that choose longer periods of faking behaviour have less faked periods that complete without anyone noticing.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{../graphics/analysis_correlation_faking_time_vs_faking_undetected.pdf}
  \caption{Both panels show a scatter plot and a regression line of the participants' average faking time in seconds compared to the ratio of undetected faking periods. In the left panel outliers, marked with orange, are included in the calculation. On the right panel outliers are excluded from the scatter plot, regression line, and statistics.}
  \label{fig:analysis:analysis_correlation_faking_time_vs_faking_undetected}
\end{figure}

Analysis of familiarity between the participants shows a positive correlation between familiarity and the detection performance ($r_s = 0.19$, $p < .001$).
This can be viewed in figure \ref{fig:analysis:analysis_pointplot_familiarity_vs_correct}.

\begin{figure}
  \centering
  \includegraphics[width=.6\textwidth]{../graphics/analysis_pointplot_familiarity_vs_correct.pdf}
  \caption{The familiarity effect on the ratio of correct accusations. Familiarity between participants was measured on a 1 to 5 likert scale, and found to positively correlate with detection performance.}
  \label{fig:analysis:analysis_pointplot_familiarity_vs_correct}
\end{figure}

In addition to the quantitative data gathered during the VR experience, the post-experience questionnaires contain some interesting information about strategies for detecting faked behaviour.
Here, I will try to use this information and compare it with the participants statistics to see how the choice of strategies affected the participants performance in detecting faked behaviour.

Participant 7, for example, claimed the following:

\begin{displayquote}
  \textit{
    It wasn't as strategy to be honest I just could tell because the body language changed quite dramatically...
    For some reason it was quite obvious for me when participant 9 faked it.
    However, not so much when participant 8 did.
  }
\end{displayquote}

Let's see if this claim can be backed by the data collected by the system.
Participant 7 accused participant 8 five times, all of these accusations were incorrect.
Participant 9, on the other hand, was accused 14 times, from which 4 (0.286 of the accusations) where correct.
This ratio is almost the same as the already discussed 0.285 average ratio of correct accusations.
From this, we might assume that the claim is correct.
However, participant 8 faked only 0.056 of the time, while participant 9 faked 0.133 of the time, making the detection of participant 9 easier.
Overall, the claim must by at least partially true, as the participant did manage to accuse one better then the other.

Some participants pointed out more concrete strategies that helped them in detecting the faked behaviour.
Specifically, they claim to notice the underlying mechanisms behind the automated faked behaviour: looped recorded baseline, automated head nods, and rotating towards the speaker.
Let's see if participants that manage to understand how the system works, in one way or another, better detect faked behaviour.

Participants 12 and 14 indicated that they detected repetitive movement and used that as an indication for faking.

\begin{displayquote}
  \textit{Look for repetetive movement + create repetetive movement for myself.}

  \hfill
  --- Participant 12

  \textit{Watching for repetitive behaviours or behaviour that looked robotic.}

  \hfill
  --- Participant 14
\end{displayquote}

Using this strategy, 0.857 of the accusations made by participant 12 were correct.
As shown in figure \ref{fig:analysis:analysis_participant12_accusations_correct}, this value is significantly higher than the average 0.285 detection performance and is expected to exceed 99\% of the players ($z = 2.38$).
Participant 14, although performed above average with a ratio of 0.533 correct accusations, didn't reach significance ($z = 0.9$).

\begin{figure}
  \centering
  \includegraphics[width=.6\textwidth]{../graphics/analysis_participant12_accusations_correct.pdf}
  \caption{A normalized histogram and estimated distribution function of the ratio of correct accusations. Participant's 12 performance is significantly high on the upper tail of the distribution.}
  \label{fig:analysis:analysis_participant12_accusations_correct}
\end{figure}

Participants 5 and 8 looked for suspicious head nods to detect faked behaviour.

\begin{displayquote}
  \textit{Found head nods a good indicator even if they were fake.}

  \hfill
  --- Participant 5

  \textit{Noticing when the other participants just noded and didn't move their hands a lot}

  \hfill
  --- Participant 8
\end{displayquote}

Although automated head nods are indeed part of the underlying mechanisms of the automated faked behaviour, the detection performance of both participants was lower than average.
Therefore, and regardless of their claims, they probably didn't manage to differentiate correctly between real and faked behaviours based on head nods.
Participant 5, however, was \textit{\textquote{pressing `Accuse' loads}}.
This comment is backed by quantitative data: whereas the average participant made an accusation every 21 seconds, participant 5 made one every 5 seconds, which is considered higher than 99\% of the players ($z = 3.02$).
This is a result of partially misunderstanding of the scoring mechanisms.
So, there is a chance that the participant actually manage to detect the automated head nods, but that this is hidden behind the excessive accusations.
Overall, there is no clear evidence that any of the participants managed to improve their detection performance based on faked head nods detection.

Lastly, participant 15 pointed out in the comments the last mechanisms to fake listening: looking at the speaker.
The participant detection performance was, however, lower than average, suggesting a failure to use this strategy to detect faked behaviour.

\begin{displayquote}
  \textit{Anyone facing me who was not talking was up for suspicion}

  \hfill
  --- Participant 15
\end{displayquote}

\section{Discussion}

The evaluation of the system provides some relatively surprising results.
The most prominent of them are the better than chance but nevertheless low accuracy in detecting faked active listening behaviours, and the high probability to start and finish faking without being noticed.
This suggests that the underlying mechanisms that automate the active listening behaviour usually manage to trick the players, and therefore are viable and useful for ECAs research.
Furthermore, two of the underlying mechanisms are unique for the current system.
First, and as previously discussed, there is almost no research in ECAs in multiparty social contexts.
Always rotating towards the speaker was chosen as the simplest approximation for the automated agent attention.
As the analysis of the participants strategies shows, participants didn't manage to use this as a clue for detecting faked behaviour.
Therefore, I would argue that this mechanism supports the automated behaviour and without a more sophisticated attention mechanism it is essential for the faked behaviour credibility.
Second, no research in ECAs deals with transitioning between human controlled and automated avatars.
The looped recorded baseline was mainly used to support this transition.
From the results, it seems that some of the participants managed to detect the loop and use that to differentiate between real and faked behaviour.
Therefore, improving the baseline behaviour might be the most important development path to achieve more reliable active listening behaviour for similar systems.
Still, the generally low detection performance shows that the recorded baseline mechanism is not too obvious nor easy to detect.
In addition, knowing that longer faking periods increase the chance of being detected implies that transition between real and faked behaviour were hard to detect.
Otherwise, participants would detect faked behaviours immediately, causing the faking period length to have no effect.

Another surprising result is related to the backchannel behaviours implemented in this project.
I used only a small set of features and applied a single, simple, animation to the avatar.
Still, no participant managed to detect the faked behaviour by noticing the automated head nods.

Also, the results demonstrate clear positive correlation between participants familiarity and detection performance.
One interpretation of this result is that participants that are familiar with each other form more accurate expectations for backchannel behaviours.
These expectations can lead them to notice body movements that are caused by the automated mechanisms.
Alternatively, they might be able to notice a decreased attention to the conversation indicated by verbal cues (e.g. ``er'' or ``ehh'' utterances).
A future study might further explore what cues helped familiar participants to improve their detection of faked behaviours.

Lastly, it is important to note that with the current implementation of the system the voice chat between the participants is always open.
This implies that participants could fake active listening behaviours will continue talking.
As this evaluation shows, participants used this capability of the system for their advantage in the individual token collection task.
The current research focuses on understanding the possibilities in dropping from the conversation and letting an automated behaviour manage ones avatar.
A further research should be carried out to understand the effects of mixing automated behaviour, such as body movement, with real one, such as voice.


\chapter{Conclusions}\label{conclusions}

The current study suggested that the ability to fake attention in telephony might be transferable to other media.
By embedding this idea in a collaborative virtual environment it explored how we signal attention and what underlying mechanisms can be used to automate these social signals.
Whereas some of the mechanisms presented in this study are known to the scientific community, others are completely new and are unique to the current project.

An experiment shows that accurate detection of faked behaviour is surprisingly hard, and that most faking periods go undetected.
Inline with previous studies, the results suggest that head nods can be automated based on surface features using ML techniques.
More interestingly, automatic rotation towards the speaker found to be a simple but convincing model of attention for automated agents in multiparty conversations.
The credibility of the proposed baseline recorded movement, however, is still unclear.
On one hand, its contribution to the reliability of automated behaviour is unquestioned, but on the other, repetitive movements sometimes gave away the fact that a user is faking.
Overall, the mechanisms for faking active listening behaviours are credible enough to trick users most of the time.
Therefore, future studies and social VR products might implement them to automate social behaviour.

More generally, this research demonstrated a possible use case for VR technologies.
The system developed in this project can be modified to test a wide array of social phenomena that are hard to test in other conditions.
Face-to-face conversations have their limitations.
Therefore, the use of VR in social studies can lead us to better understand social interaction in an increasingly technological world.

\section{Future work}

The current study only scratches the surface of exploring faked attention in CVEs.
First, as already suggested, there is room for improving the baseline recorded behaviour.
One option is to train an ML model on raw movement data.
Then, instead of playing back recorded movement with animated head nods on top, the entire movement and backchannels will be recreated by the ML algorithm.
Another option is to use a larger set of animated movements and continuously trigger appropriate animations using either ML model or hand-crafted rules.

The system developed in this project might also be used to compare different ECAs design.
For example, \citeauthor{Bailenson2005} suggest that listeners response to an ECA is more positive when the agent automatically mimics the listeners body language with 4 seconds lag (\citeyear{Bailenson2005}).
This idea somewhat contradicts theories that highlight the differences in body language between interactants based on their role in the conversation \citep[see][]{Healey2013}.
If these theories are correct, applying the body language of a listener to a speaker agent should generate inappropriate behaviour.
With relatively small modifications to the current system it might be possible to compare these ideas by automating avatars using different algorithms and measuring faking detection.
More specifically, it might be interesting to compare the current faking behaviour with the one that suggested by \citeauthor{Bailenson2005}, and with agents replicating randomly chosen non-faking player.

Results show a significant effect of familiarity between users on their ability to accurately detect faked behaviours.
Apparently, it is easier to notice when someone familiar is faking attention.
The reasons behind this effect are not clear.
A further study should be conducted to investigate this effect further.

Lastly, the current study analyzed on surface level features, like detection performance and faking time.
More interestingly, future studies might explore higher-level effects of faking on the conversation.
For example, are groups produce inferior decisions when faking is possible?
How it affects the decision making process?
Does it allow users that otherwise would be bored and inattentive to still take part in the conversation?
A positive answer to any of these questions might provide a sufficient reason for implementing the ideas proposed in this study in future technologies for group communication.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Bibliography:
%%
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plainnat}
\bibliography{thesis}


\begin{appendices}


\chapter{Pre-experience questionnaire}\label{appendix:questionnaire:pre}

\begin{itemize}

\item Participant ID: $\rule{1cm}{0.1mm}$

\item What is your age? $\rule{1cm}{0.1mm}$

\item What is your gender?

\begin{itemize}
  \item Male
  \item Female
  \item Other $\rule{4cm}{0.1mm}$
  \item Prefer not to say
\end{itemize}

\item Have you experienced virtual reality with a head mounted display?

\begin{itemize}
  \item Never
  \item Once
  \item A few times
  \item Regularly
\end{itemize}

\item Have you experienced virtual reality with the HTC Vive?

\begin{itemize}
  \item Never
  \item Once
  \item A few times
  \item Regularly
\end{itemize}

\item Please rate how well you know each of the two other participants.

\begin{tabular}{c|C C C C C}
  & Do not know him/her at all & & & & Know him/her very well \\
  Participant ID $\rule{1cm}{0.1mm}$ & 1 & 2 & 3 & 4 & 5\\
  Participant ID $\rule{1cm}{0.1mm}$ & 1 & 2 & 3 & 4 & 5\\
\end{tabular}

\end{itemize}


\chapter{Post-experience questionnaire}\label{appendix:questionnaire:post}

\begin{itemize}

\item Participant ID: $\rule{1cm}{0.1mm}$

\item What were your strategies to maximize your score?

  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}

\item What were your strategies to detect that someone is faking attention?

  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}

\item Any other comment?

  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}
  \rule{\linewidth}{0.1mm}

\end{itemize}


\chapter{Interface}\label{appendix:interface}

\begin{figure}[H]
  \includegraphics[width=\textwidth]{../graphics/interface_manual.pdf}
  \caption{Based on the HTC Vive controllers, the interface allows the players to teleport, fake active listening behaviours, and accuse other players for faking.}
  \label{fig:interface}
\end{figure}


\end{appendices}


\end{document}
